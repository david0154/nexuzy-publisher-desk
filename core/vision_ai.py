"""\nVision AI Module - Image Analysis with Watermark Detection\nVerifies images, detects watermarks, optimizes for web publishing\n"""\n\nimport sqlite3\nimport logging\nfrom typing import Dict, List, Optional, Tuple\nimport hashlib\nfrom datetime import datetime\nimport base64\nimport io\nfrom pathlib import Path\n\nlogger = logging.getLogger(__name__)\n\nclass VisionAI:\n    """Analyze images using Vision AI with watermark detection"""\n    \n    def __init__(self, db_path: str = 'nexuzy.db'):\n        self.db_path = db_path\n        self.vision_model = self._load_vision_model()\n        self.image_cache = {}  # Cache analyzed images\n    \n    def _load_vision_model(self):\n        """Load Vision AI model for image analysis - GRACEFUL FALLBACK"""\n        try:\n            from transformers import AutoImageProcessor, AutoModelForImageClassification\n            from PIL import Image\n            import torch\n            \n            logger.info("Loading Vision AI model...")\n            \n            # Try to load a lightweight vision model\n            try:\n                processor = AutoImageProcessor.from_pretrained(\n                    "google/vit-base-patch16-224",\n                    trust_remote_code=True\n                )\n                model = AutoModelForImageClassification.from_pretrained(\n                    "google/vit-base-patch16-224",\n                    trust_remote_code=True,\n                    device_map="cpu"\n                )\n                logger.info("âœ… Vision AI model loaded successfully")\n                return {'processor': processor, 'model': model}\n            except Exception as e:\n                logger.warning(f"âš ï¸  Could not load vision model: {e}")\n                logger.info("âœ… Will use heuristic image analysis (no model required)")\n                return None\n        \n        except ImportError as e:\n            logger.warning(f"âš ï¸  Vision AI dependencies not installed: {e}")\n            logger.info("ðŸ’¡ Install (optional): pip install transformers pillow torch")\n            logger.info("âœ… App will work with heuristic image analysis")\n            return None\n        except Exception as e:\n            logger.error(f"Error loading Vision AI: {e}")\n            return None\n    \n    def analyze_image(self, image_path: str, draft_id: int) -> Dict:\n        """\n        Comprehensive image analysis including watermark detection\n        \n        Args:\n            image_path: Path to image file or URL\n            draft_id: Associated draft ID\n        \n        Returns:\n            Analysis results dictionary\n        """\n        try:\n            logger.info(f"Analyzing image: {image_path}")\n            \n            # Load image\n            image_data = self._load_image(image_path)\n            if not image_data:\n                return {'status': 'failed', 'error': 'Could not load image'}\n            \n            # Generate image hash for duplicate detection\n            image_hash = self._generate_image_hash(image_data['path'])\n            \n            # Check for duplicates\n            duplicate_check = self._check_duplicate_image(image_hash)\n            if duplicate_check['is_duplicate']:\n                logger.warning(f"Duplicate image detected: {duplicate_check['original_id']}")\n            \n            # Detect watermarks\n            watermark_result = self._detect_watermark(image_data['path'])\n            \n            # Extract image metadata\n            metadata = self._extract_metadata(image_data['path'])\n            \n            # Assess image quality\n            quality_score = self._assess_image_quality(image_data['path'])\n            \n            # Optimize image\n            optimized_path = self._optimize_image(image_data['path'])\n            \n            # Convert to base64 for direct embedding\n            image_base64 = self._convert_to_base64(optimized_path or image_data['path'])\n            \n            # Compile analysis results\n            analysis = {\n                'status': 'success',\n                'image_path': image_path,\n                'image_hash': image_hash,\n                'watermark_detected': watermark_result['has_watermark'],\n                'watermark_confidence': watermark_result['confidence'],\n                'watermark_type': watermark_result['type'],\n                'quality_score': quality_score,\n                'metadata': metadata,\n                'duplicate_detected': duplicate_check['is_duplicate'],\n                'image_base64': image_base64,\n                'optimized_size': len(image_base64),\n                'recommendations': self._generate_recommendations(watermark_result, quality_score),\n                'notifications': self._generate_notifications(watermark_result, duplicate_check, quality_score)\n            }\n            \n            # Store analysis in database\n            self._store_analysis(draft_id, analysis)\n            \n            return analysis\n        \n        except Exception as e:\n            logger.error(f"Error analyzing image: {e}")\n            return {'status': 'failed', 'error': str(e)}\n    \n    def _load_image(self, image_path: str) -> Optional[Dict]:\n        """Load image from file or URL"""\n        try:\n            from PIL import Image\n            import requests\n            from io import BytesIO\n            \n            if image_path.startswith('http'):\n                # Load from URL\n                response = requests.get(image_path, timeout=10)\n                image = Image.open(BytesIO(response.content))\n                temp_path = f"/tmp/image_{hashlib.md5(image_path.encode()).hexdigest()}.png"\n                image.save(temp_path)\n            else:\n                # Load from file\n                image = Image.open(image_path)\n                temp_path = image_path\n            \n            return {\n                'path': temp_path,\n                'image': image,\n                'format': image.format,\n                'size': image.size\n            }\n        except Exception as e:\n            logger.error(f"Error loading image: {e}")\n            return None\n    \n    def _detect_watermark(self, image_path: str) -> Dict:\n        """\n        Detect watermarks in image using multiple techniques\n        """\n        try:\n            from PIL import Image\n            import numpy as np\n            \n            image = Image.open(image_path).convert('RGB')\n            img_array = np.array(image)\n            \n            # Check for text watermarks\n            text_watermark = self._detect_text_watermark(img_array)\n            \n            # Check for logo watermarks\n            logo_watermark = self._detect_logo_watermark(img_array)\n            \n            # Check for gradient watermarks\n            gradient_watermark = self._detect_gradient_watermark(img_array)\n            \n            # Compile results\n            has_watermark = any([text_watermark['detected'], logo_watermark['detected'], gradient_watermark['detected']])\n            \n            confidence = max([text_watermark['confidence'], logo_watermark['confidence'], gradient_watermark['confidence']])\n            \n            watermark_type = []\n            if text_watermark['detected']:\n                watermark_type.append('text')\n            if logo_watermark['detected']:\n                watermark_type.append('logo')\n            if gradient_watermark['detected']:\n                watermark_type.append('gradient')\n            \n            logger.info(f"Watermark detection: {has_watermark} (confidence: {confidence})")\n            \n            return {\n                'has_watermark': has_watermark,\n                'confidence': confidence,\n                'type': ', '.join(watermark_type) if watermark_type else 'none',\n                'details': {\n                    'text': text_watermark,\n                    'logo': logo_watermark,\n                    'gradient': gradient_watermark\n                }\n            }\n        \n        except Exception as e:\n            logger.error(f"Error detecting watermark: {e}")\n            return {\n                'has_watermark': False,\n                'confidence': 0,\n                'type': 'unknown',\n                'error': str(e)\n            }\n    \n    def _detect_text_watermark(self, img_array) -> Dict:\n        """Detect text-based watermarks"""\n        try:\n            import numpy as np\n            \n            # Convert to grayscale for text detection\n            gray = np.mean(img_array, axis=2)\n            \n            # Calculate edge density (text has high edges)\n            edges = np.abs(np.diff(gray))\n            edge_density = np.mean(edges)\n            \n            # Threshold-based detection\n            text_detected = edge_density > 15  # Adjust threshold based on testing\n            confidence = min(edge_density / 50, 1.0)  # Normalize to 0-1\n            \n            return {\n                'detected': text_detected,\n                'confidence': float(confidence),\n                'edge_density': float(edge_density)\n            }\n        except Exception as e:\n            logger.debug(f"Error in text watermark detection: {e}")\n            return {'detected': False, 'confidence': 0}\n    \n    def _detect_logo_watermark(self, img_array) -> Dict:\n        """Detect logo-based watermarks in corners"""\n        try:\n            import numpy as np\n            \n            height, width, _ = img_array.shape\n            \n            # Check corners where logos typically appear\n            corner_size = min(height // 4, width // 4)\n            corners = [\n                img_array[:corner_size, :corner_size],  # Top-left\n                img_array[:corner_size, -corner_size:],  # Top-right\n                img_array[-corner_size:, :corner_size],  # Bottom-left\n                img_array[-corner_size:, -corner_size:]   # Bottom-right\n            ]\n            \n            # Calculate color variance in corners\n            corner_variances = [np.var(corner) for corner in corners]\n            avg_corner_variance = np.mean(corner_variances)\n            \n            # High variance suggests distinct logo\n            logo_detected = avg_corner_variance > 500  # Adjust threshold\n            confidence = min(avg_corner_variance / 2000, 1.0)\n            \n            return {\n                'detected': logo_detected,\n                'confidence': float(confidence),\n                'variance': float(avg_corner_variance)\n            }\n        except Exception as e:\n            logger.debug(f"Error in logo watermark detection: {e}")\n            return {'detected': False, 'confidence': 0}\n    \n    def _detect_gradient_watermark(self, img_array) -> Dict:\n        """Detect gradient or overlay watermarks"""\n        try:\n            import numpy as np\n            \n            # Check for semi-transparent overlays\n            # Analyze color distribution\n            color_std = np.std(img_array, axis=(0, 1))\n            avg_color_std = np.mean(color_std)\n            \n            # Low color std suggests overlay\n            overlay_detected = avg_color_std < 30  # Adjust threshold\n            confidence = (50 - avg_color_std) / 50 if avg_color_std < 50 else 0\n            confidence = max(0, min(confidence, 1.0))\n            \n            return {\n                'detected': overlay_detected,\n                'confidence': float(confidence),\n                'color_variance': float(avg_color_std)\n            }\n        except Exception as e:\n            logger.debug(f"Error in gradient watermark detection: {e}")\n            return {'detected': False, 'confidence': 0}\n    \n    def _extract_metadata(self, image_path: str) -> Dict:\n        """Extract EXIF and other metadata"""\n        try:\n            from PIL import Image\n            from PIL.ExifTags import TAGS\n            \n            image = Image.open(image_path)\n            metadata = {\n                'format': image.format,\n                'size': image.size,\n                'width': image.width,\n                'height': image.height,\n                'mode': image.mode,\n                'exif_data': {}\n            }\n            \n            # Extract EXIF data if available\n            try:\n                exif_data = image.getexif()\n                for tag_id, value in exif_data.items():\n                    tag_name = TAGS.get(tag_id, tag_id)\n                    metadata['exif_data'][tag_name] = str(value)[:100]  # Limit to 100 chars\n            except:\n                pass\n            \n            return metadata\n        except Exception as e:\n            logger.error(f"Error extracting metadata: {e}")\n            return {}\n    \n    def _assess_image_quality(self, image_path: str) -> float:\n        """Assess overall image quality (0-1 scale)"""\n        try:\n            from PIL import Image\n            import numpy as np\n            \n            image = Image.open(image_path)\n            img_array = np.array(image)\n            \n            # Check dimensions\n            min_dimension = min(image.width, image.height)\n            size_score = min(min_dimension / 1920, 1.0)  # Good quality if > 1920px\n            \n            # Check color depth\n            if image.mode == 'RGB':\n                color_score = 1.0\n            elif image.mode == 'RGBA':\n                color_score = 0.9\n            else:\n                color_score = 0.7\n            \n            # Check blur (using Laplacian variance)\n            if image.mode != 'RGB':\n                img_array = Image.new('RGB', image.size, color=image.getexif().get(274, 1))\n            \n            # Simple blur detection\n            gray = np.mean(img_array, axis=2) if len(img_array.shape) == 3 else img_array\n            edges = np.abs(np.diff(gray))\n            blur_score = min(np.mean(edges) / 20, 1.0)\n            \n            # Combined quality score\n            quality = (size_score * 0.3 + color_score * 0.3 + blur_score * 0.4)\n            \n            return float(max(0, min(quality, 1.0)))\n        \n        except Exception as e:\n            logger.error(f"Error assessing image quality: {e}")\n            return 0.5\n    \n    def _optimize_image(self, image_path: str) -> Optional[str]:\n        """Optimize image for web publishing"""\n        try:\n            from PIL import Image\n            \n            image = Image.open(image_path)\n            \n            # Resize if too large\n            max_dimension = 1920\n            if max(image.width, image.height) > max_dimension:\n                ratio = max_dimension / max(image.width, image.height)\n                new_size = (int(image.width * ratio), int(image.height * ratio))\n                image = image.resize(new_size, Image.Resampling.LANCZOS)\n            \n            # Convert to RGB if necessary\n            if image.mode in ('RGBA', 'LA', 'P'):\n                image = image.convert('RGB')\n            \n            # Save optimized version\n            optimized_path = f"{image_path[:-4]}_optimized.jpg"\n            image.save(optimized_path, 'JPEG', quality=85, optimize=True)\n            \n            logger.info(f"Image optimized: {optimized_path}")\n            return optimized_path\n        \n        except Exception as e:\n            logger.warning(f"Error optimizing image: {e}")\n            return None\n    \n    def _convert_to_base64(self, image_path: str) -> str:\n        """Convert image to base64 for direct embedding"""\n        try:\n            with open(image_path, 'rb') as img_file:\n                return base64.b64encode(img_file.read()).decode('utf-8')\n        except Exception as e:\n            logger.error(f"Error converting image to base64: {e}")\n            return ""\n    \n    def _generate_image_hash(self, image_path: str) -> str:\n        """Generate perceptual hash of image for duplicate detection"""\n        try:\n            from PIL import Image\n            import numpy as np\n            \n            image = Image.open(image_path).resize((8, 8)).convert('L')\n            pixels = np.array(image)\n            avg_pixel = np.mean(pixels)\n            hash_string = ''.join(['1' if p > avg_pixel else '0' for p in pixels.flatten()])\n            return hash_string\n        except Exception as e:\n            logger.error(f"Error generating image hash: {e}")\n            return hashlib.md5(str(image_path).encode()).hexdigest()\n    \n    def _check_duplicate_image(self, image_hash: str) -> Dict:\n        """Check if similar image already exists"""\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # Look for matching hash\n            cursor.execute('''\n                SELECT id, draft_id, similarity_score FROM image_analysis\n                WHERE image_hash = ? LIMIT 1\n            ''', (image_hash,))\n            \n            result = cursor.fetchone()\n            conn.close()\n            \n            if result:\n                return {\n                    'is_duplicate': True,\n                    'original_id': result[0],\n                    'draft_id': result[1],\n                    'similarity': result[2]\n                }\n            \n            return {'is_duplicate': False}\n        \n        except Exception as e:\n            logger.error(f"Error checking duplicates: {e}")\n            return {'is_duplicate': False}\n    \n    def _generate_recommendations(self, watermark_result: Dict, quality_score: float) -> List[str]:\n        """Generate recommendations based on analysis"""\n        recommendations = []\n        \n        if watermark_result['has_watermark']:\n            if watermark_result['confidence'] > 0.7:\n                recommendations.append(f"Replace image - Strong {watermark_result['type']} watermark detected")\n            else:\n                recommendations.append(f"Consider replacing - Possible {watermark_result['type']} watermark detected")\n        \n        if quality_score < 0.6:\n            recommendations.append("Image quality is low - Consider using a higher resolution version")\n        elif quality_score < 0.8:\n            recommendations.append("Image quality could be improved")\n        \n        if not recommendations:\n            recommendations.append("Image looks good for publishing")\n        \n        return recommendations\n    \n    def _generate_notifications(self, watermark_result: Dict, duplicate_check: Dict, quality_score: float) -> List[Dict]:\n        """Generate user notifications"""\n        notifications = []\n        \n        if watermark_result['has_watermark']:\n            notifications.append({\n                'type': 'warning',\n                'severity': 'high' if watermark_result['confidence'] > 0.7 else 'medium',\n                'message': f"Watermark detected ({watermark_result['type']}) with {int(watermark_result['confidence']*100)}% confidence",\n                'action': 'Consider replacing the image'\n            })\n        \n        if duplicate_check.get('is_duplicate'):\n            notifications.append({\n                'type': 'info',\n                'severity': 'low',\n                'message': f"Similar image already used in draft {duplicate_check['draft_id']}",\n                'action': 'Verify this is intentional'\n            })\n        \n        if quality_score < 0.6:\n            notifications.append({\n                'type': 'warning',\n                'severity': 'medium',\n                'message': f"Low image quality score ({int(quality_score*100)}%)",\n                'action': 'Use a higher resolution version if available'\n            })\n        \n        return notifications\n    \n    def _store_analysis(self, draft_id: int, analysis: Dict):\n        """Store analysis results in database"""\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute('''\n                INSERT INTO image_analysis\n                (draft_id, image_path, image_hash, watermark_detected, watermark_confidence, \n                 quality_score, metadata, analysis_json, created_at)\n                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ''', (\n                draft_id,\n                analysis['image_path'],\n                analysis['image_hash'],\n                analysis['watermark_detected'],\n                analysis['watermark_confidence'],\n                analysis['quality_score'],\n                str(analysis.get('metadata', {})),\n                str(analysis),\n                datetime.now().isoformat()\n            ))\n            \n            conn.commit()\n            conn.close()\n            logger.info(f"Analysis stored for draft {draft_id}")\n        \n        except Exception as e:\n            logger.error(f"Error storing analysis: {e}")\n